import re
import json
import os
import sys
import io
import uuid
import time
import requests
from pprint import pprint
import google.generativeai as genai
from datetime import datetime

# ‚úÖ Set UTF-8 encoding for standard output
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
# ‚úÖ Configure paths
JSON_DIR = r"ADD_PATH_HERE"
INSERT_URL = "http://127.0.0.1:8000/api/insert_articles/"
HEADERS = {"Content-Type": "application/json"}

# ‚úÖ Base directories
BASE_DIR = r"ADD_PATH_HERE"
OUTPUT_DIR = r"ADD_PATH_HERE"
CONFIG_FILE = "./config.json"
DJANGO_API_URL = "http://127.0.0.1:8000/api/insert_articles/"

# ‚úÖ Load API key
def load_api_key(config_file):
    try:
        with open(config_file, 'r', encoding='utf-8') as file:
            config = json.load(file)
            return config.get("api_key")
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"‚ùå Error reading config file: {e}")
        return None

API_KEY = load_api_key(CONFIG_FILE)
if API_KEY is None:
    sys.exit("‚ùå API key is missing. Please check your config file.")

# ‚úÖ Configure AI API
genai.configure(api_key=API_KEY)

# ‚úÖ Find `MatchedNewsData-*` directories
def find_matched_news_dirs(base_dir):
    return [
        os.path.join(base_dir, d)
        for d in os.listdir(base_dir)
        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith("MatchedNewsData")
    ]

# ‚úÖ Read JSON files
def read_json_files(directory):
    articles = []
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            filepath = os.path.join(directory, filename)
            with open(filepath, 'r', encoding='utf-8') as file:
                json_data = json.load(file)
                articles.append(json_data)
    return articles

# ‚úÖ AI Article Processing (Can be commented out if already generated)
def process_articles_with_ai(articles):
    article_strings = [json.dumps(article, ensure_ascii=False, indent=4) for article in articles]
    articles_combined = "\n".join(article_strings)

    # ‚úÖ AI prompts
    title_prompt = "Bu haber makalelerine dayanarak, 3-4 kelimelik nesnel bir ba≈ülƒ±k olu≈üturun:"
    short_summary_prompt = "Bu haber makalelerine dayanarak, 10-50 karakter arasƒ±nda kƒ±sa, betimleme i√ßermeyen, salt bilgi i√ßeren bir √∂zet olu≈üturun:"
    detailed_summary_prompt = "Bu haber makalelerine dayanarak, detaylƒ± ve salt bilgi i√ßeren bir √∂zet olu≈üturun:"

    # ‚úÖ Initialize AI model
    model = genai.GenerativeModel('gemini-1.5-flash')

    # ‚úÖ Add delays to prevent hitting quota limits
    time.sleep(5)  
    try:
        title_response = model.generate_content(f"{title_prompt}\n{articles_combined}")
        title = title_response.text.strip()
    except Exception as e:
        print(f"‚ùå Error generating title: {e}")
        title = "Title generation failed"

    time.sleep(5)
    try:
        short_summary_response = model.generate_content(f"{short_summary_prompt}\n{articles_combined}")
        short_summary = short_summary_response.text.strip()
    except Exception as e:
        print(f"‚ùå Error generating short summary: {e}")
        short_summary = "Short summary failed"

    time.sleep(5)
    try:
        detailed_summary_response = model.generate_content(f"{detailed_summary_prompt}\n{articles_combined}")
        detailed_summary = detailed_summary_response.text.strip()
    except Exception as e:
        print(f"‚ùå Error generating detailed summary: {e}")
        detailed_summary = "Detailed summary failed"

    # ‚úÖ Generate Unique ID for the article
    article_id = str(uuid.uuid4())

    # ‚úÖ Extract sources as a list
    sources = list(set([article.get("source", "Unknown") for article in articles if "source" in article]))

    # ‚úÖ Create structured output
    output = {
        "id": None,
        "articleId": article_id,
        "title": title,
        "content": "",
        "summary": short_summary,
        "longerSummary": detailed_summary,
        "category": None,
        "tags": [],
        "source": sources,
        "location": None,
        "popularityScore": 0,
        "createdAt": None,
        "image": None,
        "priority": None
    }
    return output

# ‚úÖ Save JSON output
def save_json_output(data):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_filename = f"objectified_summary_{timestamp}.json"
    output_filepath = os.path.join(OUTPUT_DIR, output_filename)

    with open(output_filepath, 'w', encoding='utf-8') as output_file:
        json.dump(data, output_file, ensure_ascii=False, indent=4)

    print(f"‚úÖ Output saved locally at {output_filepath}")
    return output_filepath

# ‚úÖ Function to send JSON files one by one
def send_json_files():
    if not os.path.exists(JSON_DIR):
        print(f"‚ùå Directory not found: {JSON_DIR}")
        return
    
    json_files = [f for f in os.listdir(JSON_DIR) if f.endswith(".json")]
    
    if not json_files:
        print("‚ùå No JSON files found in objectified_jsons directory!")
        return

    print(f"üîç Found {len(json_files)} objectified JSON files. Sending them to the backend...")

    for json_file in json_files:
        json_path = os.path.join(JSON_DIR, json_file)

        try:
            # ‚úÖ Load JSON data
            with open(json_path, 'r', encoding='utf-8') as file:
                data = json.load(file)

            # ‚úÖ Debugging - Print data before sending
            print(f"\nüîπ Sending file: {json_file} to backend...")
            print("üìú JSON Data (First 300 characters):", json.dumps(data, indent=2)[:300])

            # ‚úÖ Send POST request
            response = requests.post(INSERT_URL, json=data, headers=HEADERS)
            response_json = response.json()

            # ‚úÖ Debugging - Print server response
            print(f"üìú Backend Response (Status {response.status_code}): {response_json}")

            if response.status_code == 201:
                print(f"‚úÖ Successfully sent {json_file}!")
            else:
                print(f"‚ùå Failed to send {json_file} (Server Response): {response.text}")

        except json.JSONDecodeError:
            print(f"‚ùå Error: Invalid JSON format in {json_file}. Skipping but NOT deleting it.")
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Network error while sending {json_file}: {str(e)}")
            print("‚ö†Ô∏è Keeping the JSON file for retry.")
        except Exception as e:
            print(f"‚ùå Unexpected error processing {json_file}: {str(e)}")

    print("‚úÖ All objectified JSONs have been processed.")


# ‚úÖ Main Function
def main():
    news_dirs = find_matched_news_dirs(BASE_DIR)

    if not news_dirs:
        print("‚ùå No `MatchedNewsData-*` directories found!")
        return

    print(f"üîç Found {len(news_dirs)} directories to process.")

    # ‚úÖ Delete old articles before inserting new ones
    print("üóë Deleting old articles before inserting new ones...")
    try:
        requests.get("http://127.0.0.1:8000/api/delete_articles/")
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error deleting old articles: {e}")

    for news_dir in news_dirs:
        print(f"üìÇ Processing: {news_dir}")
        articles = read_json_files(news_dir)

        if not articles:
            print(f"‚ö†Ô∏è No articles found in {news_dir}, skipping...")
            continue

        # ‚úÖ Ensure no duplicate processing
        unique_titles = set()
        filtered_articles = []

        for article in articles:
            title = article.get("title", "").strip()
            if title and title not in unique_titles:
                unique_titles.add(title)
                filtered_articles.append(article)

        if not filtered_articles:
            print(f"‚ö†Ô∏è No new unique articles found in {news_dir}, skipping...")
            continue

        # ‚úÖ AI Processing (COMMENT THIS IF NOT NEEDED)
        processed_data = process_articles_with_ai(filtered_articles)

        # ‚úÖ Save locally
        save_json_output(processed_data)

        # Step 1: Send new JSON files **without deleting them unless uploaded successfully**
        send_json_files()

        print("‚úÖ Process completed successfully!")

    print("‚úÖ All directories processed successfully!")

# ‚úÖ Run the script
if __name__ == "__main__":
    main()
